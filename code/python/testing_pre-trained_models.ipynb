{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from time import process_time\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from helpers import pre_processing_wlan_utils as preprocess_utils\n",
    "from helpers import classifier_wlan_spectral_utils as classifier_utils\n",
    "from helpers import tr_models as tr_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Set which task you want to solve. This value will be used to select the right labels for the loaded dataset.\n",
    "#The labels of the dataset are for the following tasks: 'phy' (L1 Technology identification), 'frames' (L2 frame characterization), 'app-type' (L7 App characterization), or 'app' (L7 App identification). \n",
    "#The results of the paper are for the three last tasks.\n",
    "task = 'app'\n",
    "label = preprocess_utils.label_index[task]\n",
    "num_classes = preprocess_utils.num_classes[task]\n",
    "labels_string = preprocess_utils.labels_string[task]\n",
    "print(\"Label id: \", label)\n",
    "print(\"Num classes in that label: \", num_classes)\n",
    "print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dataset does not contain the unknown label class (L2 frames that were generated with an unknown app), so lets remove that label.\n",
    "if (task == 'app') or (task == 'app-type'):\n",
    "    num_classes = num_classes-1\n",
    "    labels_string = labels_string[0:num_classes]\n",
    "    print(\"Label id: \", label)\n",
    "    print(\"Num classes in that label: \", num_classes)\n",
    "    print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set lenght of the sequences\n",
    "seq_length = 3000\n",
    "\n",
    "#Set type of padding. \n",
    "padding = 'post'\n",
    "\n",
    "#Set path to dataset folder. All the files from the dataset can be downloaded from https://zenodo.org/record/5208201\n",
    "dataset_folder = '../../dataset/waveforms/'\n",
    "\n",
    "#Set name of dataset file. In this case we are using once of the balanced dataset (filename_balanced.mat)\n",
    "dataset_filename = 'waveforms_2G_n_SNR_'+task+'_balanced.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's select the pre-configured model we want to load. You can choose between CNN and GRU (RNN). The hyperparameters will be selected based on a combination between \n",
    "#model type and task. The model type is also used to pre-process the shape of the input data, which is different for the CNN and the GRU. \n",
    "model_type = 'CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use the CNN-based pretrained model created on 26-08-2021 that solves the classification task 'app' with input sequence 3K IQ samples\n",
    "#For testing other models, please check the filename and set the prefix_time, the task, and the input length as the filename indicates. \n",
    "#In this case the prefix filename for the pre-trained model is: 260821100426_TC_Spectrum_model_CNN_input_length_3000_num_classes_7_task_app\n",
    "prefix_time_pretrained_model = '260821100426'\n",
    "prefix_filenames = prefix_time_pretrained_model+'_TC_Spectrum_model_'+model_type+'_input_length_'+str(seq_length)+'_num_classes_'+str(num_classes)+'_task_'+task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_filename = 'notebook_results/pre_trained_models/'+prefix_filenames+'_classifier.h5'\n",
    "pre_trained_model = load_model(trained_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get X and Y without padding/truncation nor scaling. The function get_raw_xy_spectrum returns the L1 packets (IQ samples) and all the labels associated to them. \n",
    "Xraw, Yraw = classifier_utils.get_raw_xy_spectrum(dataset_folder,dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pad/truncate the L1 packets to a given lenght.\n",
    "print(\"Padding/Truncating sequence to a length of \",str(seq_length))\n",
    "X = classifier_utils.pad_or_trunc_x_and_scale(Xraw, seq_length, padding, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets select the labels of the classification task and generate the one-shot labels \n",
    "print(\"Generate one-shot labels\")\n",
    "Y = classifier_utils.get_one_hot_labels(Yraw, num_classes, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a seed for pseudo random generator for splitting the dataset\n",
    "seed = 42\n",
    "print(\"Performing data splitting\")\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = classifier_utils.get_xy_4_training(X,Y,seed)\n",
    "print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapt the shape of the dataset to match the model type.\n",
    "print('Starting data preparation and training for model ', model_type)\n",
    "X_train, X_val, X_test = classifier_utils.reshape_for_model(model_type, X_train, X_val, X_test)\n",
    "print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation Training set\")\n",
    "loss_acc_train = pre_trained_model.evaluate(X_train, Y_train)\n",
    "print(\"Training Loss:\", loss_acc_train[0])\n",
    "print(\"Training Accuracy:\", loss_acc_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation Validating set\")\n",
    "loss_acc_val = pre_trained_model.evaluate(X_val, Y_val)\n",
    "print(\"Validation Loss:\", loss_acc_val[0])\n",
    "print(\"Validation Accuracy:\", loss_acc_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation Testing set\")\n",
    "loss_acc_test = pre_trained_model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss:\",loss_acc_train[0])\n",
    "print(\"Test Accuracy:\",loss_acc_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing confusion matrix')\n",
    "Y_pred=np.argmax(pre_trained_model.predict(X_test),1)\n",
    "Y_true=np.argmax(Y_test,1)\n",
    "cm_norm = confusion_matrix(Y_true, Y_pred, normalize='true')\n",
    "cm = confusion_matrix(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix nomarlized', cm_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix no nomarlized', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing precision, recall, and fscore')\n",
    "#'macro' average: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "prf_macro = precision_recall_fscore_support(Y_true, Y_pred, average='macro')\n",
    "print(\"Precision:\",prf_macro[0])\n",
    "print(\"Recall:\", prf_macro[1])\n",
    "print(\"FScore:\", prf_macro[2])\n",
    "print(\"Test Accuracy:\", loss_acc_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'micro' average: Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "prf_micro = precision_recall_fscore_support(Y_true, Y_pred, average='micro')\n",
    "print(\"Precision:\",prf_micro[0])\n",
    "print(\"Recall:\", prf_micro[1])\n",
    "print(\"FScore:\", prf_micro[2])\n",
    "print(\"Test Accuracy:\", loss_acc_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also defined a function to compute and store the confusion matix in a pdf file.\n",
    "classifier_utils.compute_and_save_conf_matrix(pre_trained_model, X_test, Y_test, labels_string, cm_dir = './', filename_prefix = prefix_filenames, precision = \"{:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing prediction time on Training dataset')\n",
    "start = process_time()\n",
    "pre_trained_model.predict(X_train)\n",
    "end = process_time()\n",
    "print('The prediction time (in secs) was: ', end-start)\n",
    "print('The prediction time (in secs) per sample was: ', (end-start)/len(X_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:traf_rec] *",
   "language": "python",
   "name": "conda-env-traf_rec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
