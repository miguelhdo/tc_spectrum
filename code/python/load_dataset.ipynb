{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from helpers import pre_processing_wlan_utils as preprocess_utils\n",
    "from helpers import classifier_wlan_spectral_utils as classifier_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Set which task you want to solve. This value will be used to select the right labels for the loaded dataset.\n",
    "#The three task can be 'phy', 'frames', 'app-type', or, 'app'\n",
    "task = 'app'\n",
    "label = preprocess_utils.label_index[task]\n",
    "num_classes = preprocess_utils.num_classes[task]\n",
    "labels_string = preprocess_utils.labels_string[task]\n",
    "print(\"Label id: \", label)\n",
    "print(\"Num classes in that label: \", num_classes)\n",
    "print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dataset does not contain the unknown label class (L2 frames that were generated with an unknown app), so lets remove that label.\n",
    "if (task == 'app') or (task == 'app-type'):\n",
    "    num_classes = num_classes-1\n",
    "    labels_string = labels_string[0:num_classes]\n",
    "    print(\"Label id: \", label)\n",
    "    print(\"Num classes in that label: \", num_classes)\n",
    "    print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set lenght of the sequences\n",
    "seq_length = 3000\n",
    "\n",
    "#Set type of padding. \n",
    "padding = 'post'\n",
    "\n",
    "#Set path to dataset folder. All the files from the dataset can be downloaded from https://zenodo.org/record/5208201\n",
    "dataset_folder = '../../dataset/waveforms/'\n",
    "\n",
    "#Set name of dataset file. In this case we are using once of the balanced dataset (filename_balanced.mat)\n",
    "dataset_filename = 'waveforms_2G_n_SNR_'+task+'_balanced.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get X and Y without padding/truncation nor scaling. The function get_raw_xy_spectrum returns the L1 packets (IQ samples) and all the labels associated to them. \n",
    "Xraw, Yraw = classifier_utils.get_raw_xy_spectrum(dataset_folder,dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pad/truncate the L1 packets to a given lenght.\n",
    "print(\"Padding/Truncating sequence to a length of \",str(seq_length))\n",
    "X = classifier_utils.pad_or_trunc_x_and_scale(Xraw, seq_length, padding, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets select the labels of the classification task and generate the one-shot labels \n",
    "print(\"Generate one-shot labels\")\n",
    "Y = classifier_utils.get_one_hot_labels(Yraw, num_classes, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a seed for pseudo random generator\n",
    "seed = 42\n",
    "print(\"Performing data splitting\")\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = classifier_utils.get_xy_4_training(X,Y,seed)\n",
    "print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to get not the L1 but L2 packets, simple use the following function \n",
    "Xraw_bytes, Yraw_bytes = classifier_utils.get_raw_xy_bytes(dataset_folder,dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pad/truncate the L2 packets to the max length of a L2 packet found in the dataset\n",
    "l2_seq_length = classifier_utils.get_max_length_L2_packet(Xraw_bytes)\n",
    "print(\"The max length of a L2 packet was \",l2_seq_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Padding/Truncating sequence to a length of \",str(l2_seq_length))\n",
    "X_byte = classifier_utils.pad_or_trunc_x_and_scale_bytes(Xraw_bytes, l2_seq_length, padding, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets select the labels of the classification task and generate the one-shot labels \n",
    "print(\"Generate one-shot labels\")\n",
    "Y_byte = classifier_utils.get_one_hot_labels(Yraw_bytes, num_classes, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As before, let's a seed for pseudo random generator and split the dataset\n",
    "seed = 42\n",
    "print(\"Performing data splitting\")\n",
    "X_byte_train, X_byte_val, X_byte_test, Y_byte_train, Y_byte_val, Y_byte_test = classifier_utils.get_xy_4_training(X_byte,Y_byte,seed)\n",
    "print(X_byte_train.shape,X_byte_val.shape, X_byte_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc_spectrum",
   "language": "python",
   "name": "tc_spectrum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
