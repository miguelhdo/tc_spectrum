{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from helpers import pre_processing_wlan_utils as preprocess_utils\n",
    "from helpers import classifier_wlan_spectral_utils as classifier_utils\n",
    "from helpers import tr_models as tr_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Set which task you want to solve. This value will be used to select the right labels for the loaded dataset.\n",
    "#The labels of the dataset are for the following tasks: 'phy' (L1 Technology identification), 'frames' (L2 frame characterization), 'app-type' (L7 App characterization), or 'app' (L7 App identification). \n",
    "#The results of the paper are for the three last tasks.\n",
    "task = 'app-type'\n",
    "label = preprocess_utils.label_index[task]\n",
    "num_classes = preprocess_utils.num_classes[task]\n",
    "labels_string = preprocess_utils.labels_string[task]\n",
    "print(\"Label id: \", label)\n",
    "print(\"Num classes in that label: \", num_classes)\n",
    "print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dataset does not contain the unknown label class (L2 frames that were generated with an unknown app), so lets remove that label.\n",
    "if (task == 'app') or (task == 'app-type'):\n",
    "    num_classes = num_classes-1\n",
    "    labels_string = labels_string[0:num_classes]\n",
    "    print(\"Label id: \", label)\n",
    "    print(\"Num classes in that label: \", num_classes)\n",
    "    print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set lenght of the sequences\n",
    "seq_length = 3000\n",
    "\n",
    "#Set type of padding. \n",
    "padding = 'post'\n",
    "\n",
    "#Set path to dataset folder. All the files from the dataset can be downloaded from https://zenodo.org/record/5208201\n",
    "dataset_folder = '../../dataset/waveforms/'\n",
    "\n",
    "#Set name of dataset file. In this case we are using once of the balanced dataset (filename_balanced.mat)\n",
    "dataset_filename = 'waveforms_2G_n_SNR_'+task+'_balanced.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get X and Y without padding/truncation nor scaling. The function get_raw_xy_spectrum returns the L1 packets (IQ samples) and all the labels associated to them. \n",
    "Xraw, Yraw = classifier_utils.get_raw_xy_spectrum(dataset_folder,dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pad/truncate the L1 packets to a given lenght.\n",
    "print(\"Padding/Truncating sequence to a length of \",str(seq_length))\n",
    "X = classifier_utils.pad_or_trunc_x_and_scale(Xraw, seq_length, padding, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets select the labels of the classification task and generate the one-shot labels \n",
    "print(\"Generate one-shot labels\")\n",
    "Y = classifier_utils.get_one_hot_labels(Yraw, num_classes, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a seed for pseudo random generator for splitting the dataset\n",
    "seed = 42\n",
    "print(\"Performing data splitting\")\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = classifier_utils.get_xy_4_training(X,Y,seed)\n",
    "print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's select the pre-configured model we want to load. You can choose between CNN and RNN. The hyperparameters will be selected based on a combination between \n",
    "#model type and task. The model type is also used to pre-process the shape of the input data, which is different for the CNN and the RNN. \n",
    "model_type = 'CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapt the shape of the dataset to match the model type.\n",
    "print('Starting data preparation and training for model ', model_type)\n",
    "X_train, X_val, X_test = classifier_utils.reshape_for_model(model_type, X_train, X_val, X_test)\n",
    "print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets generate a string to use as prefix to name some output files such as the model (hd5) and the confusion matrix (pdf)\n",
    "now = datetime.now()\n",
    "datenow = now.strftime('%d%m%y%H%M%S')\n",
    "prefix_time = str(datenow)\n",
    "prefix_filenames = prefix_time+'_TC_Spectrum_model_'+model_type+'_input_length_'+str(seq_length)+'_num_classes_'+str(num_classes)+'_task_'+task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now time for create the model and train it. \n",
    "#The expected accuracy with an input size of 3K samples with a CNN are: task 'frame'  ~99%, task 'app-type' ~97%, task 'app' ~90.44% \n",
    "result, model = classifier_utils.create_and_train_model_tc_spectrum(model_type, task, seq_length, num_classes, prefix_filenames, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model loss in training: \", result['Training'][0])\n",
    "print(\"Model accuracy in training: \", result['Training'][1])\n",
    "print(\"Model loss in validation: \", result['Validation'][0])\n",
    "print(\"Model accuracy in validation: \", result['Validation'][1])\n",
    "print(\"Model loss in test: \", result['Test'][0])\n",
    "print(\"Model accuracy in test: \", result['Test'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The inference time on training dataset is\", result['prediction_time_training']['time_pred'], '. It was computed using', result['prediction_time_training']['n_samples'],'samples with an average inference time per sample of', result['prediction_time_training']['t_sample'])\n",
    "print(\"The inference time on test dataset is\", result['prediction_time_testing']['time_pred'], '. It was computed using', result['prediction_time_testing']['n_samples'],'samples with an average inference time per sample of', result['prediction_time_testing']['t_sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output dictionary with the results from the model training also contains other results/metrics that you can access such as the confusion matrix, precision, recall, fscore, and support.\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's export the results in json format\n",
    "classifier_utils.save_results_to_json(prefix_filenames, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also defined a function to compute and store the confusion matix in a pdf file.\n",
    "classifier_utils.compute_and_save_conf_matrix(model, X_test, Y_test, labels_string, cm_dir = './', filename_prefix = prefix_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:traf_rec] *",
   "language": "python",
   "name": "conda-env-traf_rec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
